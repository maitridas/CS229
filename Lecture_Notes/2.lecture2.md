## Outline
1. Linear Regression
2. Batch/Stochastic Gradient
3. Normal Equation

## Process
1. Feed Training set to a learning algorithm
2. Generates a hypothesis which gives us the output

![Problem](./images/lecture2/img1.JPG)

## How do you represent the hypoyhetis
![Problem](./images/lecture2/img2.JPG)

![Problem](./images/lecture2/img3.JPG)

![Problem](./images/lecture2/img4.JPG)

![Problem](./images/lecture2/img5.JPG)

![Problem](./images/lecture2/img6.JPG)

![Problem](./images/lecture2/img7.JPG)

xi , yi -> ith training example

-  Okay. So, um, and I think the final bit of notation, um, I've been writing h of x as a function of the features of the house, as a function of the size and number of bedrooms of the house. Um, sometimes we emphasize that h depends both on the parameters Theta and on the input features x. Um, we're going to use h_Theta of x to emphasize that the hypothesis depends both on the parameters and on the, you know, input features x

![Problem](./images/lecture2/img8.JPG)

- This is J(theta)
- we add a 1/2 to make the calculation of derivative easier
- we minimize the difference
- Why square -> some reason for a generalisation because its kinda like a gaussian then.

## Gradient Descent 
- start with some theta (say theta is a vector of all zeros)
- keep changing theta to reduce J(theta)

![Problem](./images/lecture2/img9.JPG)

![Problem](./images/lecture2/img10.JPG)

- " a:= a+1" -> means assigning
- " a=b " -> asserting a = b
- alpha is learning rate

For only one example-

![Problem](./images/lecture2/img11.JPG)

![Problem](./images/lecture2/img12.JPG)

All term will be 0 in the partial derivative except thetaj

![Problem](./images/lecture2/img13.JPG)

![Problem](./images/lecture2/img14.JPG)

![Problem](./images/lecture2/img15.JPG)

![Problem](./images/lecture2/img16.JPG)

- alpha too large can overshoot the minima
- alpha too small too longer to train

![Problem](./images/lecture2/img17.JPG)

Whole batch gradient descent is slow, As we read through entire data set then backprop so its super slow .

We use Stocastic gradient descent.

![Problem](./images/lecture2/img18.JPG)

But SGD is noisy because we are updating in a batch but in average works fine.
So as you run stochastic gradient descent- stochastic gradient descent will actually, never quite converge. In- with- with batch gradient descent, it kind of went to the global minimum and stopped right, uh, with stochastic gradient descent even as you won't run it, the parameters will oscillate and won't ever quite converge because you're always running around looking at different houses and trying to do better than just that one house- and that one house- and that one house. Uh, but when you have a very large data-set, stochastic gradient descent, allows your implementation- allows you algorithm to make much faster progress. Uh, and so, um, uh, uh- and so when you have very large data-sets, stochastic gradient descent is used much more in practice than batch gradient descent. 

Traditionally the whole batch gradient descent is called batch gradient descent.

right, and this- this one I'm gonna present next is called the normal equation. It works only for linear regression, doesn't work for any of the other algorithms I talk about later this quarter. 

J, right. There's a function mapping from parameters to the real numbers. 

![Problem](./images/lecture2/img19.JPG)

![Problem](./images/lecture2/img20.JPG)

![Problem](./images/lecture2/img21.JPG)

![Problem](./images/lecture2/img22.JPG)

![Problem](./images/lecture2/img23.JPG)

![Problem](./images/lecture2/img24.JPG)

Ah and I got these four numbers by taking, um, the definition of F and taking the derivative with respect to A_1, 1 and plugging that here. Ah, taking the derivative with respect to A_1,2 and plugging that here and taking the derivative with respect to the remaining elements and plugging them here which- which was 0. 

## Deerivation of normal equation

the broad outline of what we're going to do is we're going to take J of Theta. Right. That's the cost function. Um, take the derivative with respect to Theta. Right. Ah, since Theta is a vector so you want to take the derivative with respect to Theta and you know well, how do you minimize a function? You take derivatives with [NOISE] respect to Theta and set it equal to 0. And then you solve for the value of Theta so that the derivative is 0. Right. The- the minimum, you know, the maximum and minimum of a function is where the derivative is equal to 0. So- so how you derive the normal equation is take this vector. Ah, so J of Theta maps from a vector to a real number. So we'll, take the derivatives respect to Theta set it to 0,0 and solve for Theta and then we end up with a formula for Theta that lets you just, um, ah, you know, immediately go to the global minimum of the- of the cost function J of Theta. 

![Problem](./images/lecture2/img25.JPG)

![Problem](./images/lecture2/img26.JPG)

![Problem](./images/lecture2/img27.JPG)

![Problem](./images/lecture2/img28.JPG)

![Problem](./images/lecture2/img29.JPG)

![Problem](./images/lecture2/img30.JPG)

![Problem](./images/lecture2/img31.JPG)

![Problem](./images/lecture2/img32.JPG)

![Problem](./images/lecture2/img33.JPG)

![Problem](./images/lecture2/img34.JPG)

![Problem](./images/lecture2/img35.JPG)

![Problem](./images/lecture2/img36.JPG)

![Problem](./images/lecture2/img37.JPG)

![Problem](./images/lecture2/img38.JPG)

Normal Equation

![Problem](./images/lecture2/img39.JPG)

![Problem](./images/lecture2/img40.JPG)

what if X is non-invertible? Uh, what that usually means is you have have redundant features, uh, that your features are linearly dependent. Uh, but if you use something called the pseudo inverse, you kind of get the right answer if that's the case. Although I think the, uh, even more right answer is if you have linearly dependent features, probably means you have the same feature repeated twice, and I will usually go and figure out what features are actually repeated, leading to this problem. 